# Comparing Means (How a Qualitative Variable Relates to a Quantitative One)

## Difference between Two Means[\[1\]](#_ftn1)

It is much more common for a researcher to be interested in the difference between means than in the specific values of the means themselves. This section covers how to test for differences between means from two separate groups of subjects. Note that we already learned in the chapter on graphing how to visually depict a comparison of two means/medians using boxplots (@sec-box-plots).

We take as an example the data from the "Animal Research" case study, previously described when discussing confidence intervals (@sec-using-confidence-intervals).[\[2\]](#_ftn2) As a reminder, students rated (on a 7-point scale) whether they thought animal research is wrong. The sample sizes, means, and variances are shown separately for males and females in @tbl-meansvaranimalresearch.

|     |           |     |       |     |          |     |              |     |
|:---:|:---------:|:---:|:-----:|:---:|:--------:|:---:|:------------:|:---:|
|     | **Group** |     | **n** |     | **Mean** |     | **Variance** |     |
|     |  Females  |     |  17   |     |  5.353   |     |    2.743     |     |
|     |   Males   |     |  17   |     |  3.882   |     |    2.985     |     |

: Means and Variances in Animal Research study. {#tbl-meansvaranimalresearch}

As you can see, the females rated animal research as more wrong than did the males. This sample difference between the female mean of 5.35 and the male mean of 3.88 is 1.47. However, the gender difference in this particular sample is not very important. What is important is whether there is a difference in the *population* means.

In order to test whether there is a difference between population means, we are going to make three assumptions:

1.  The two populations have the same variance. This assumption is called the assumption of homogeneity of variance.

2.  The populations are normally distributed.

3.  Each value is sampled independently from each other value. This assumption requires that each subject provide only one value. If a subject provides two scores, then the scores are not independent.

One could look at these assumptions in much more detail, but suffice it to say that small-to-moderate violations of assumptions 1 and 2 do not make much difference. It is important not to violate assumption 3.

We saw the following general formula for significance testing in the section on testing a single mean:

$$
\text{t} = \frac{\text{statistic-hypothesized value}}{\text{estimated standard error of the statistic}}
$$

In this case, our statistic is the difference between sample means and our hypothesized value is 0. The hypothesized value is the null hypothesis that the difference between population means is 0.

We continue to use the data from the "Animal Research" case study and will compute a significance test on the difference between the mean score of the females and the mean score of the males. For this calculation, we will make the three assumptions specified above.

The first step is to compute the statistic, which is simply the difference between means.

$$
M_1 - M_2 = 5.3529 - 3.8824 = 1.4705
$$

Since the hypothesized value is 0, we do not need to subtract it from the statistic.

The next step is to compute the estimate of the standard error of the statistic. In this case, the statistic is the difference between means, so the estimated standard error of the statistic is ($S_{M1}-{_M}_2$). Recall from the [relevant section](http://onlinestatbook.com/2/sampling_distributions/samplingdist_diff_means.html) in the chapter on sampling distributions that the formula for the standard error of the difference between means is:

$$
σ_{M1-M2} = \sqrt{\frac{σ^2_1}{n_1}+\frac{σ^2_2}{n_12}} = \sqrt{\frac{σ^2}{n}+\frac{σ^2}{n}} = \sqrt{\frac{2σ^2}{n}}
$$

In order to estimate this quantity, we estimate σ^2^ and use that estimate in place of σ^2^. Since we are assuming the two population variances are the same, we estimate this variance by averaging our two sample variances. Thus, our estimate of variance is computed using the following formula:

$$
\text{MSE}= \frac{s^2_1+s^2_2}{2}
$$

where MSE is our estimate of $σ^2$. In this example,

$$
\text{MSE} = (2.743 + 2.985)/2 = 2.864.
$$

Since n (the number of scores in each group) is 17,

$$
S_{M1-M2} = \sqrt{\frac{2MSE}{n}} = \sqrt{\frac{(2)(2.864)}{17}} = 0.5805
$$

The next step is to compute t by plugging these values into the formula:

$$
t = 1.4705/.5805 = 2.533.
$$

Finally, we compute the probability of getting a $t$ as large or larger than 2.533 or as small or smaller than -2.533. To do this, we need to know the degrees of freedom. The degrees of freedom is the number of independent estimates of variance on which $MSE$ is based. This is equal to ($n_1$ - 1) + ($n_2$ - 1), where $n_1$ is the sample size of the first group and $n_2$ is the sample size of the second group. For this example, $n_1$ = $n_2$ = 17. When $n_1$ = $n_2$, it is conventional to use "$n$" to refer to the sample size of each group. Therefore, the degrees of freedom is 16 + 16 = 32.

Once we have the degrees of freedom, we can use a t distribution calculator[\[3\]](#_ftn3) to find the probability. @fig-2tailprob shows that the probability value for a two-tailed test is 0.0164. The two-tailed test is used when the null hypothesis can be rejected regardless of the direction of the effect. As shown in @fig-2tailprob, it is the probability of a t \< -2.533 or a t \> 2.533.

![The two-tailed probability.](Images/Ch8/2tailprob.png){#fig-2tailprob}

The results of a one-tailed test are shown in @fig-1tailprob. As you can see, the probability value of 0.0082 is half the value for the two-tailed test.

![The one-tailed probability.](Images/Ch8/1tailprob.png){#fig-1tailprob}

### Formatting Data for Computer Analysis

Most computer programs that compute t tests require your data to be in a specific form. Consider the data in @tbl-exampledata.

|     |             |     |             |     |
|-----|-------------|-----|-------------|-----|
|     | **Group 1** |     | **Group 2** |     |
|     | 3           |     | 2           |     |
|     | 4           |     | 6           |     |
|     | 5           |     | 8           |     |

: Example data. {#tbl-exampledata}

Here there are two groups, each with three observations. To format these data for a computer program, you normally have to use two variables: the first specifies the group the subject is in and the second is the score itself. The reformatted version of the data in @tbl-exampledata is shown in @tbl-reformatdata.

|     |       |     |       |     |
|-----|-------|-----|-------|-----|
|     | **G** |     | **Y** |     |
|     | 1     |     | 3     |     |
|     | 1     |     | 4     |     |
|     | 1     |     | 5     |     |
|     | 2     |     | 2     |     |
|     | 2     |     | 6     |     |
|     | 2     |     | 8     |     |

: Reformatted data. {#tbl-reformatdata}

Using statistical software, we’d find that the t value is -0.718, the df = 4, and p = 0.512.

## Pairwise Comparisons Among Multiple Means[\[4\]](#_ftn4)

Many experiments are designed to compare more than two conditions. We will take as an example the case study "Smiles and Leniency."[\[5\]](#_ftn5) In this study, the effect of different types of smiles on the leniency shown to a person was investigated. An obvious way to proceed would be to do a t test of the difference between each group mean and each of the other group means. This procedure would lead to the six comparisons shown in @tbl-feltmisneutral.

|                       |                               |                               |
|:------------------:|:------------------------:|:------------------------:|
|  felt vs. miserable   |  ![](Images/Ch8/feltjpg.png)  | ![](Images/Ch8/miserable.png) |
|   felt vs. neutral    |  ![](Images/Ch8/feltjpg.png)  |  ![](Images/Ch8/neutral.png)  |
| miserable vs. neutral | ![](Images/Ch8/miserable.png) |  ![](Images/Ch8/neutral.png)  |

: Six Comparisons among Means. {#tbl-feltmisneutral}

The problem with this approach is that if you did this analysis, you would have six chances to make a Type I error. Therefore, if you were using the 0.05 significance level, the probability that you would make a Type I error on at least one of these comparisons is greater than 0.05. The more means that are compared, the more the Type I error rate is inflated. @fig-pairwisecompfmean shows the number of possible comparisons between pairs of means (pairwise comparisons) as a function of the number of means. If there are only two means, then only one comparison can be made. If there are 12 means, then there are 66 possible comparisons.

![Number of pairwise comparisons as a function of the number of means.](Images/Ch8/pairwisecompfmean.png){#fig-pairwisecompfmean}

@fig-type1error shows the probability of a Type I error as a function of the number of means. As you can see, if you have an experiment with 12 means, the probability is about 0.70 that at least one of the 66 comparisons among means would be significant even if all 12 population means were the same.

![Probability of a Type I error as a function of the number of means.](Images/Ch8/type1error.png){#fig-type1error}

The Type I error rate can be controlled using a test called the Tukey Honestly Significant Difference test or Tukey HSD for short. The Tukey HSD test is one example of a multiple comparison test, but several alternatives are frequently used, such as the Bonferroni correction. Regardless of the exact method used for a multiple comparison test, the interpretation of results is similar. The Tukey HSD is based on a variation of the t distribution that takes into account the number of means being compared. This distribution is called the studentized range distribution.

Normally, statistical software will make all the necessary calculations for you in the background. But to illustrate what sorts of calculations the software is relying on, let's return to the leniency study to see how to compute the Tukey HSD test. You will see that the computations are very similar to those of an independent-groups t test. The steps are outlined below:

1.  Compute the means and variances of each group. They are shown below.

|     |               |     |          |     |              |     |
|:---:|:-------------:|:---:|:--------:|:---:|:------------:|:---:|
|     | **Condition** |     | **Mean** |     | **Variance** |     |
|     |     False     |     |   5.37   |     |     3.34     |     |
|     |     Felt      |     |   4.91   |     |     2.83     |     |
|     |   Miserable   |     |   4.91   |     |     2.11     |     |
|     |    Neutral    |     |   4.12   |     |     2.32     |     |

2.  Compute MSE, which is simply the mean of the variances. It is equal to 2.65.

3.  Compute

$$
Q=\frac{M_i-M_j}{\sqrt{\frac{MSE}{n}}}
$$

for each pair of means, where $M_i$ is one mean, $M_j$ is the other mean, and $n$ is the number of scores in each group. For these data, there are 34 observations per group. The value in the denominator is 0.279.

4.  Compute p for each comparison using a Studentized Range Calculator.[\[6\]](#_ftn6) The degrees of freedom is equal to the total number of observations minus the number of means. For this experiment, df = 136 - 4 = 132.

The tests for these data are shown in @tbl-6pairwisecomp.

|     |                     |     |               |     |       |     |       |     |
|:---:|:-------------------:|:---:|:-------------:|:---:|:-----:|:---:|:-----:|:---:|
|     |   **Comparison**    |     | **M~i~-M~j~** |     | **Q** |     | **p** |     |
|     |    False - Felt     |     |     0.46      |     | 1.65  |     | 0.649 |     |
|     |  False - Miserable  |     |     0.46      |     | 1.65  |     | 0.649 |     |
|     |   False - Neutral   |     |     1.25      |     | 4.48  |     | 0.010 |     |
|     |  Felt - Miserable   |     |     0.00      |     | 0.00  |     | 1.000 |     |
|     |   Felt - Neutral    |     |     0.79      |     | 2.83  |     | 0.193 |     |
|     | Miserable - Neutral |     |     0.79      |     | 2.83  |     | 0.193 |     |

: Six Pairwise Comparisons. {#tbl-6pairwisecomp}

The only significant comparison is between the false smile and the neutral smile.

It is not unusual to obtain results that on the surface appear paradoxical. For example, these results appear to indicate that (a) the false smile is the same as the miserable smile, (b) the miserable smile is the same as the neutral control, and (c) the false smile is different from the neutral control. This apparent contradiction is avoided if you are careful not to accept the null hypothesis when you fail to reject it. The finding that the false smile is not significantly different from the miserable smile does not mean that they are really the same. Rather it means that there is not convincing evidence that they are different. Similarly, the non-significant difference between the miserable smile and the control does not mean that they are the same. The proper conclusion is that the false smile is higher than the control and that the miserable smile is either (a) equal to the false smile, (b) equal to the control, or (c) somewhere in-between.

The assumptions of the Tukey test are essentially the same as for an independent-groups t test: normality, homogeneity of variance, and independent observations. The test is quite robust to violations of normality. Violating homogeneity of variance can be more problematical than in the two-sample case since the MSE is based on data from all groups. The assumption of independence of observations is important and should not be violated.

### Computer Analysis

For most computer programs, you should format your data the same way you do for an independent-groups t test. The only difference is that if you have, say, four groups, you would code each group as 1, 2, 3, or 4 rather than just 1 or 2.

### Tukey's Test Need Not be a Follow-Up to ANOVA

Some textbooks introduce the Tukey test only as a follow-up to an analysis of variance. There is no logical or statistical reason why you should not use the Tukey test even if you do not compute an ANOVA (or even know what one is). If you or your instructor do not wish to take our word for this, see the excellent article on this and other issues in statistical analysis by Leland Wilkinson and the APA Board of Scientific Affairs' Task Force on Statistical Inference, published in the *American Psychologist*, August 1999, Vol. *54*, No. 8, 594–604.

## Analysis of Variance (ANOVA)[\[7\]](#_ftn7)

**Analysis of Variance (ANOVA)** is a statistical method used to test differences between two or more means. It may seem odd that the technique is called "Analysis of Variance" rather than "Analysis of Means." As you will see, the name is appropriate because inferences about means are made by analyzing variance.

ANOVA is used to test general rather than specific differences among means. This can be seen best by example. In the case study "Smiles and Leniency,"[\[8\]](#_ftn8) the effect of different types of smiles on the leniency shown to a person was investigated. Four different types of smiles (neutral, false, felt, miserable) were investigated. In the prior section, we learned how to test differences among means. The results from the Tukey HSD test are shown in @tbl-6pairwisecomp2.

|     |                     |     |               |     |       |     |       |     |
|-----|---------------------|-----|---------------|-----|-------|-----|-------|-----|
|     | **Comparison**      |     | **M~i~-M~j~** |     | **Q** |     | **p** |     |
|     | False - Felt        |     | 0.46          |     | 1.65  |     | 0.649 |     |
|     | False - Miserable   |     | 0.46          |     | 1.65  |     | 0.649 |     |
|     | False - Neutral     |     | 1.25          |     | 4.48  |     | 0.010 |     |
|     | Felt - Miserable    |     | 0.00          |     | 0.00  |     | 1.000 |     |
|     | Felt - Neutral      |     | 0.79          |     | 2.83  |     | 0.193 |     |
|     | Miserable - Neutral |     | 0.79          |     | 2.83  |     | 0.193 |     |

: Six Pairwise Comparisons. {#tbl-6pairwisecomp2}

Notice that the only significant difference is between the False and Neutral conditions.

ANOVA tests the non-specific null hypothesis that all four population means are equal. That is,

$$
μ_{false} = μ_{felt}~ = μ_{miserable} = μ_{neutral}
$$

This non-specific null hypothesis is sometimes called the omnibus null hypothesis. When the omnibus null hypothesis is rejected, the conclusion is that at least one population mean is different from at least one other mean. However, since the ANOVA does not reveal which means are different from which, it offers less specific information than the Tukey HSD test. The Tukey HSD is therefore preferable to ANOVA in this situation. Some textbooks introduce the Tukey test only as a follow-up to an ANOVA. However, there is no logical or statistical reason why you should not use the Tukey test even if you do not compute an ANOVA.

You might be wondering why you should learn about ANOVA when the Tukey test is better. One reason is that there are complex types of analyses that can be done with ANOVA and not with the Tukey test. A second is that ANOVA is by far the most commonly-used technique for comparing means, and it is important to understand ANOVA in order to understand research reports.

------------------------------------------------------------------------

[\[1\]](#_ftnref1) This section is adapted from David M. Lane. “Difference between Two Means (Independent Groups).” *Online Statistics Education: A Multimedia Course of Study*. <http://onlinestatbook.com/2/tests_of_means/difference_means.html>

[\[2\]](#_ftnref2) <http://onlinestatbook.com/2/case_studies/animal_research.html>

[\[3\]](#_ftnref3) <http://onlinestatbook.com/2/calculators/t_dist.html>

[\[4\]](#_ftnref4) This section is adapted from David M. Lane. “All Pairwise Comparisons Among Means.” *Online Statistics Education: A Multimedia Course of Study*. <http://onlinestatbook.com/2/tests_of_means/pairwise.html>

[\[5\]](#_ftnref5) <http://onlinestatbook.com/2/case_studies/leniency.html>

[\[6\]](#_ftnref6) <http://onlinestatbook.com/2/calculators/studentized_range_dist.html>

[\[7\]](#_ftnref7) This section is adapted from David M. Lane. “Introduction.” *Online Statistics Education: A Multimedia Course of Study*. <http://onlinestatbook.com/2/analysis_of_variance/intro.html>

[\[8\]](#_ftnref8) <http://onlinestatbook.com/2/case_studies/leniency.html>
